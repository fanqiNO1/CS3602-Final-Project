## Result

| id | encoder_cell | dropout | embed_size | hidden_size | num_layer | batch_size | lr | max_epoch | dev_acc | dev_fscore | other info |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | LSTM | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 71.7318 | 79.3826/75.0782/77.1704 | baseline |
| 2 | LSTM | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 70.6145 | 79.8864/73.3055/76.4546 | bimodel |
| 3 | LSTM | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 76.0894 | 78.8618/80.9176/79.8765 | correct |
| 4 | LSTM | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 69.8324 | 74.3590/72.5756/73.4565 | multihead |
| 5 | LSTM | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 71.7318 | 79.3826/75.0782/77.1704 | scheduler |
| 6 | LSTM | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 72.6257 | 80.8296/75.1825/77.9038 | chinese |
| 7 | LSTM | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 76.3128 | 79.2300/81.5433/80.3700 | chinese+correct+scheduler |
| 8 | Transformer | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 87.2626 | 99.5277/87.9041/93.3555 | transformer |
| 9 | BERT | 0.1 | 768 | 768 | 12 | 32 | 1-e6 | 128 | 99.7700 | 98.4000/98.4000/98.4000 | BERT (fine-tuned) |
| 10 | Transformer | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 87.4860 | 99.6471/88.3212/93.6429 | transformer+correct+scheduler |
| 11 | GRU | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 70.8380 | 80.5936/73.6184/76.9482 | GRU |
| 12 | RNN | 0.2 | 768 | 512 | 2 | 32 | 1e-3 | 100 | 71.2849 | 77.1123/75.1825/76.1352 | RNN |